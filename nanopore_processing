#!/bin/bash

# nanopore reads come in fast5 format, in a folder called "fast5".  Inside this folder are a bunch of different subdirectories that have the reads binned.  Can either run the basecalling algorith as an array to do each folder separately (takes less time), or run albacore with the recursive flag which looks into each folder.  From what I can tell, it would take almost 2 weeks to run the basecalling with the recursive flag so its probably better to do the array and concatenate later.

# running the basecalling program Albacore
# array program took < 1 day to complete

#!/bin/bash
#SBATCH -J "albacore_array_run"
#SBATCH -n 1               # Use n cores for one job
#SBATCH -a 0-136
#SBATCH -t 2-00:00                # Runtime in D-HH:MM
#SBATCH -p shared                # Partition to submit to
#SBATCH --mem=24G            # Memory pool for all cores
#SBATCH -o outfile.%A.out	# File to which STDOUT will be written
#SBATCH -e outfile.%A.err	# File to which STDERR will be written
#SBATCH --mail-type=ALL           # Type of email notification- BEGIN,END,FAIL,ALL
#SBATCH --mail-user=andrew_gehrke@fas.harvard.edu # Email to which notifications will be sent

# Run
/n/home05/agehrke/.conda/envs/albacore/bin/read_fast5_basecaller.py \
-f FLO-MIN106 \
-k SQK-LSK109 \
-i /n/boslfs/INSTRUMENTS/illumina/Nanopore/AGehrke/20180920_2010_AGehrkeH3/fast5/$SLURM_ARRAY_TASK_ID \
-t 40 \
-s /n/regal/srivastava_lab/gehrke/albacore_output/$SLURM_ARRAY_TASK_ID \
-o fastq \
-q 100000

--------------------------------------------------------------------------------------------------------------

# or, to run recursively:
# note, likely need way more than 2 days to do this

#!/bin/bash
#SBATCH -J "albacore_recursive_run"
#SBATCH -n 1               # Use n cores for one job
#SBATCH -t 2-00:00                # Runtime in D-HH:MM
#SBATCH -p shared                # Partition to submit to
#SBATCH --mem=24G            # Memory pool for all cores
#SBATCH -o outfile.%A.out	# File to which STDOUT will be written
#SBATCH -e outfile.%A.err	# File to which STDERR will be written
#SBATCH --mail-type=ALL           # Type of email notification- BEGIN,END,FAIL,ALL
#SBATCH --mail-user=andrew_gehrke@fas.harvard.edu # Email to which notifications will be sent

# Run
/n/home05/agehrke/.conda/envs/albacore/bin/read_fast5_basecaller.py \
-f FLO-MIN106 \
-k SQK-LSK109 \
-i /n/boslfs/INSTRUMENTS/illumina/Nanopore/AGehrke/20180920_2010_AGehrkeH3/fast5 \
-t 40 \
-s /net/fs2k02/srv/export/srivastava_lab/share_root/genome_raw_reads_FINAL/albacore_recursive  \
-o fastq \
-q 100000 \
-r

--------------------------------------------------------------------------------------------------------------

#rest of the current workflow is assuming the basecalling was performed as an array (and thus a seperate folder for each bin with pass/fail inside)

# combine all of the "pass" fastq files from all the different output folders of albacore into one fastq file:

#!/bin/bash
#SBATCH -J "combine_fastq"
#SBATCH -n 1               # Use n cores for one job
#SBATCH -t 0-05:00                # Runtime in D-HH:MM
#SBATCH -p shared                # Partition to submit to
#SBATCH --mem=16G            # Memory pool for all cores
#SBATCH -o outfile.%A.out	# File to which STDOUT will be written
#SBATCH -e outfile.%A.err	# File to which STDERR will be written
#SBATCH --mail-type=ALL           # Type of email notification- BEGIN,END,FAIL,ALL
#SBATCH --mail-user=andrew_gehrke@fas.harvard.edu # Email to which notifications will be sent

# Run

for i in {0..136}
do
cd /n/regal/srivastava_lab/gehrke/albacore_output/$i/workspace/pass
cat *.fastq >> /n/regal/srivastava_lab/gehrke/final_albacore_combined.fastq
done

--------------------------------------------------------------------------------------------------------------

# with this concatenated fastq file, can map to reference genome using minimap2

#!/bin/bash
#SBATCH -J "minimap_alignment"
#SBATCH -n 1               # Use n cores for one job
#SBATCH -t 0-05:00                # Runtime in D-HH:MM
#SBATCH -p shared                # Partition to submit to
#SBATCH --mem=24G            # Memory pool for all cores
#SBATCH -o outfile.%A.out	# File to which STDOUT will be written
#SBATCH -e outfile.%A.err	# File to which STDERR will be written
#SBATCH --mail-type=ALL           # Type of email notification- BEGIN,END,FAIL,ALL
#SBATCH --mail-user=andrew_gehrke@fas.harvard.edu # Email to which notifications will be sent

#load module
module load minimap2/2.9-fasrc01

# Run
minimap2 -ax map-ont /net/fs2k02/srv/export/srivastava_lab/share_root/ATAC_data/ATAC_DoveTail_Data/raw_reads_cat/hmi_genome.fa /n/regal/srivastava_lab/gehrke/final_albacore_combined.fastq > /n/regal/srivastava_lab/gehrke/ont_alignment.sam

# Output will be a SAM file that needs to be converted to BAM

--------------------------------------------------------------------------------------------------------------

# to get a list of regions that contain NO nanopore coverage:

bedtools bamtobed -i albacore_output.sorted_FINAL.bam > albacore_output.sorted_FINAL.bed

bedtools merge -i albacore_output.sorted_FINAL.bed > albacore_output.sorted_FINAL_MERGE.bed

bedtools genomecov -i albacore_output.sorted_FINAL_MERGE.bed -bga -g /net/fs2k02/srv/export/srivastava_lab/share_root/ATAC_data/ATAC_DoveTail_Data/raw_reads_cat/hm.chrom.sizes > albacore_output.sorted_FINAL_MERGE.bedgraph

less albacore_output.sorted_FINAL_MERGE.bedgraph | grep -w 0$ > albacore_output.sorted_FINAL_MERGE.bedgraph_no_coverage.txt



